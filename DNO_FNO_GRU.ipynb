{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Concatenate, Multiply\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('./changhua_data.csv')\n",
    "\n",
    "# Extract columns\n",
    "# Assume: First column is time, second column is flow, third to ninth are rainfall data\n",
    "times = pd.to_datetime(data.iloc[:, 0].values)  # Convert time to datetime\n",
    "flows = data.iloc[:, 1].values.reshape(-1, 1)\n",
    "rainfalls = data.iloc[:, 2:].values\n",
    "\n",
    "# Create sequences for time-series prediction\n",
    "def create_sequences(data, target, input_steps, output_steps):\n",
    "    X, y, times_seq = [], [], []\n",
    "    for i in range(len(data) - input_steps - output_steps + 1):\n",
    "        X.append(data[i:(i + input_steps), :])\n",
    "        y.append(target[(i + input_steps):(i + input_steps + output_steps), 0])\n",
    "        times_seq.append(times[i + input_steps:(i + input_steps + output_steps)])\n",
    "    return np.array(X), np.array(y), np.array(times_seq)\n",
    "\n",
    "input_steps = 12  # Use past 12 hours\n",
    "output_steps = 6  # Predict next 6 hours\n",
    "\n",
    "# Data preprocessing\n",
    "scaler_flow = MinMaxScaler()\n",
    "flows_scaled = scaler_flow.fit_transform(flows)\n",
    "\n",
    "scaler_rainfall = MinMaxScaler()\n",
    "rainfalls_scaled = scaler_rainfall.fit_transform(rainfalls)\n",
    "\n",
    "# Combine rainfall and flow data for sequence creation\n",
    "combined_data = np.concatenate((rainfalls_scaled, flows_scaled), axis=1)\n",
    "\n",
    "# Create sequences\n",
    "X, y, times_seq = create_sequences(combined_data, flows_scaled, input_steps, output_steps)\n",
    "\n",
    "# Train-test split 不按照时间顺序分割\n",
    "# X_train, X_test, y_train, y_test, times_train, times_test = train_test_split(X, y, times_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train-test split using time-based split to maintain sequence continuity 按照时间顺序分割\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "times_train, times_test = times_seq[:split_index], times_seq[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepONet implementation\n",
    "# Branch Network: Takes the rainfall data as input\n",
    "branch_input = Input(shape=(input_steps, X_train.shape[2] - 1), name='branch_input')\n",
    "branch_lstm = LSTM(64, activation='relu')(branch_input)\n",
    "branch_output = Dense(32, activation='relu')(branch_lstm)\n",
    "\n",
    "# Trunk Network: Takes the flow data as input\n",
    "trunk_input = Input(shape=(input_steps, 1), name='trunk_input')\n",
    "trunk_lstm = LSTM(64, activation='relu')(trunk_input)\n",
    "trunk_output = Dense(32, activation='relu')(trunk_lstm)\n",
    "\n",
    "# Replace pointwise multiplication with FNO and GRU layers\n",
    "# Fourier Neural Operator (FNO) layer\n",
    "from tensorflow.keras.layers import Conv1D, LayerNormalization\n",
    "\n",
    "fno_layer_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(branch_output[:, None, :])\n",
    "fno_layer_2 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(fno_layer_1)\n",
    "fno_layer_2 = tf.squeeze(fno_layer_2, axis=1)\n",
    "\n",
    "# GRU layers\n",
    "gru_layer_1 = LSTM(32, return_sequences=True, activation='relu')(tf.expand_dims(fno_layer_2, axis=1))\n",
    "gru_layer_2 = LSTM(32, activation='relu')(gru_layer_1)\n",
    "\n",
    "# Combine FNO and GRU output\n",
    "combined = Multiply()([trunk_output, gru_layer_2])\n",
    "combined_output = Dense(output_steps, activation='linear')(combined)\n",
    "\n",
    "# Model definition\n",
    "model = Model(inputs=[branch_input, trunk_input], outputs=combined_output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit([X_train[:, :, :-1], X_train[:, :, -1:]], y_train, epochs=100, batch_size=16, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate([X_test[:, :, :-1], X_test[:, :, -1:]], y_test)\n",
    "print(f'Test Loss: {evaluation[0]}, Test MAE: {evaluation[1]}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict([X_test[:, :, :-1], X_test[:, :, -1:]])\n",
    "\n",
    "# Only keep the first future step predictions to avoid overlap\n",
    "predictions = predictions[:, 0].reshape(-1, 1)\n",
    "y_test = y_test[:, 0].reshape(-1, 1)\n",
    "\n",
    "# Inverse transform the predicted flows to original scale\n",
    "predicted_flows = scaler_flow.inverse_transform(predictions)\n",
    "y_test_inverse = scaler_flow.inverse_transform(y_test)\n",
    "y_test_inverse = scaler_flow.inverse_transform(y_test)\n",
    "\n",
    "# Display predictions\n",
    "results = pd.DataFrame({'Actual Flow': y_test_inverse.flatten(), 'Predicted Flow': predicted_flows.flatten()})\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test_inverse.flatten(), predicted_flows.flatten())\n",
    "mape = mean_absolute_percentage_error(y_test_inverse.flatten(), predicted_flows.flatten())\n",
    "r2 = r2_score(y_test_inverse.flatten(), predicted_flows.flatten())\n",
    "print(f'MAE: {mae}, MAPE: {mape}, R^2: {r2}')\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rainfall-flow dual-axis chart for actual vs predicted flows along with aggregated rainfall\n",
    "fig, ax1 = plt.subplots(figsize=(18, 10))\n",
    "draw_len = len(y_test_inverse)\n",
    "\n",
    "# Use first 100 data points for plotting\n",
    "time_steps = np.arange(draw_len)\n",
    "aggregated_rainfall = scaler_rainfall.inverse_transform(X_test[:draw_len, :, :-1].reshape(-1, X_test.shape[2] - 1)).sum(axis=1).reshape(draw_len, -1).mean(axis=1)\n",
    "\n",
    "# Plot aggregated rainfall as a bar chart, pointing downwards\n",
    "ax1.bar(time_steps, aggregated_rainfall, color='tab:green', alpha=0.5, label='Aggregated Rainfall')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlabel('Time Steps')\n",
    "ax1.set_ylabel('Aggregated Rainfall (mm)')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_title('Rainfall and Flow Relationship')\n",
    "\n",
    "# Apply smoothing to actual and predicted flow\n",
    "actual_flow = y_test_inverse[:draw_len, 0]\n",
    "predicted_flow = predicted_flows[:draw_len, 0]\n",
    "\n",
    "# Plot actual and predicted flow\n",
    "ax2 = ax1.twinx() \n",
    "ax2.plot(time_steps, actual_flow, label='Actual Flow', color='blue', alpha=0.7)\n",
    "ax2.plot(time_steps, predicted_flow, label='Predicted Flow', color='red', linestyle='dashed', alpha=0.7)\n",
    "\n",
    "ax2.set_ylabel('Flow (m^3/s)')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted flows 全部时间步\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(y_test_inverse.flatten(), label='Actual Flow')\n",
    "plt.plot(predicted_flows.flatten(), label='Predicted Flow')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Flow')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted Flow')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18 (default, Sep 11 2023, 08:28:20) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5e36ac6a21e329c2cec267b08e4f28884519c7e5682f29504bd17199cc3d203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
